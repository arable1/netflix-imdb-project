{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29c77373",
   "metadata": {},
   "source": [
    "1.\tImport libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "823cbd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8735fb07",
   "metadata": {},
   "source": [
    "2.\tLoad datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92836591",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df = pd.read_csv(\"../data/raw/netflix_movies_and_shows.csv\")  # IMDb dataset\n",
    "titles_df = pd.read_csv(\"../data/raw/netflix_titles.csv\")           # Old dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d20709",
   "metadata": {},
   "source": [
    "3.\tBasic info & shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b9bbbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IMDb dataset\n",
      "Shape: (5283, 11)\n",
      "index                  int64\n",
      "id                    object\n",
      "title                 object\n",
      "type                  object\n",
      "description           object\n",
      "release_year           int64\n",
      "age_certification     object\n",
      "runtime                int64\n",
      "imdb_id               object\n",
      "imdb_score           float64\n",
      "imdb_votes           float64\n",
      "dtype: object\n",
      "\n",
      "Titles dataset\n",
      "Shape: (8807, 12)\n",
      "show_id         object\n",
      "type            object\n",
      "title           object\n",
      "director        object\n",
      "cast            object\n",
      "country         object\n",
      "date_added      object\n",
      "release_year     int64\n",
      "rating          object\n",
      "duration        object\n",
      "listed_in       object\n",
      "description     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "for name, df in [(\"IMDb\", imdb_df), (\"Titles\", titles_df)]:\n",
    "    print(f\"\\n{name} dataset\")\n",
    "    print(\"Shape:\", df.shape)\n",
    "    print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebf5732",
   "metadata": {},
   "source": [
    "4. Missing values summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82d62384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IMDb missing values:\n",
      "index                   0\n",
      "id                      0\n",
      "title                   0\n",
      "type                    0\n",
      "description             5\n",
      "release_year            0\n",
      "age_certification    2285\n",
      "runtime                 0\n",
      "imdb_id                 0\n",
      "imdb_score              0\n",
      "imdb_votes             16\n",
      "dtype: int64\n",
      "\n",
      "Titles missing values:\n",
      "show_id            0\n",
      "type               0\n",
      "title              0\n",
      "director        2634\n",
      "cast             825\n",
      "country          831\n",
      "date_added        10\n",
      "release_year       0\n",
      "rating             4\n",
      "duration           3\n",
      "listed_in          0\n",
      "description        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for name, df in [(\"IMDb\", imdb_df), (\"Titles\", titles_df)]:\n",
    "    print(f\"\\n{name} missing values:\")\n",
    "    print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1c25d1",
   "metadata": {},
   "source": [
    "5. Duplicates check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a5e3331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IMDb duplicates: 0\n",
      "\n",
      "Titles duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "for name, df in [(\"IMDb\", imdb_df), (\"Titles\", titles_df)]:\n",
    "    print(f\"\\n{name} duplicates:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fb1d95",
   "metadata": {},
   "source": [
    "6. Overlap check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a43c558c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common titles: 3911\n",
      "Unique to IMDb: 1324\n",
      "Unique to Titles: 4890\n"
     ]
    }
   ],
   "source": [
    "imdb_titles = set(imdb_df[\"title\"].str.lower().str.strip())\n",
    "titles_titles = set(titles_df[\"title\"].str.lower().str.strip())\n",
    "common_titles = imdb_titles & titles_titles\n",
    "print(f\"Common titles: {len(common_titles)}\")\n",
    "print(f\"Unique to IMDb: {len(imdb_titles - common_titles)}\")\n",
    "print(f\"Unique to Titles: {len(titles_titles - common_titles)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0703a004",
   "metadata": {},
   "source": [
    "7. Example preview of common and unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbcb44e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample common titles: ['50m2', 'the delivery boy', 'muran', 'bareilly ki barfi', 'arq', 'thunder force', 'due date', 'one by two', 'abla fahita: drama queen', 'the outpost']\n",
      "\n",
      "Sample unique IMDb: ['ok kanmani', 'kayko and kokosh', \"nikki glaser: bangin'\", 'dany boon: des hauts-de-france', 'lupin the third: the castle of cagliostro', 'the seven deadly sins: prisoners of the sky', 'the rite', 'the goop lab', 'dunkirk', 'dancing on glass']\n",
      "\n",
      "Sample unique Titles: ['escape from mr. lemoncello’s library', '20 feet from stardom', 'oddbods: the festive menace', \"the witness who didn't see anything\", 'el patrón, radiografía de un crimen', 'rake', 'the duchess', 'chhota bheem & ganesh', 'ancient aliens', 'high on the hog: how african american cuisine transformed america']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSample common titles:\", list(common_titles)[:10])\n",
    "print(\"\\nSample unique IMDb:\", list(imdb_titles - common_titles)[:10])\n",
    "print(\"\\nSample unique Titles:\", list(titles_titles - common_titles)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452aa388",
   "metadata": {},
   "source": [
    "8. Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fabd9e",
   "metadata": {},
   "source": [
    "## What the side‑by‑side check tells us\n",
    "\n",
    "\t•\tIMDb dataset (target present): 5,283 rows, clean, almost no missing except age_certification (~43%) and a few description/imdb_votes.\n",
    "\t•\tTitles dataset (metadata only): 8,807 rows, rich fields (director, cast, country, rating, listed_in, duration) but no target.\n",
    "\t•\tOverlap: 3,911 titles match by title (case/trim) alone. That means ~74% of IMDb rows can be enriched immediately with extra metadata; ~26% will remain IMDb-only unless we fuzzy match.\n",
    "\n",
    "## Recommendation\n",
    "\n",
    "\t•\tUse IMDb as the base (it has imdb_score, your target).\n",
    "\t•\tDo a left join from IMDb → Titles on (title, release_year) after normalizing titles. This gives the best of both worlds without losing any IMDb rows.\n",
    "\t•\tOptional later: try fuzzy matching for some of the 1,324 IMDb‑only titles to lift enrichment coverage (worth it only if the extra features are needed).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77de28c5",
   "metadata": {},
   "source": [
    "9. Normalize keys for a clean join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26b71407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_title(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Lowercase and strip whitespace for matching.\"\"\"\n",
    "    return s.str.strip().str.lower()\n",
    "\n",
    "imdb_df[\"title_norm\"] = norm_title(imdb_df[\"title\"])\n",
    "titles_df[\"title_norm\"] = norm_title(titles_df[\"title\"])\n",
    "\n",
    "# Align join_year with release_year for strict match\n",
    "titles_df[\"join_year\"] = titles_df[\"release_year\"]\n",
    "\n",
    "# Metadata columns we want to pull from Titles dataset\n",
    "meta_cols = [\"director\",\"cast\",\"country\",\"date_added\",\"rating\",\"duration\",\"listed_in\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ed7918",
   "metadata": {},
   "source": [
    "10. Create unique tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5977144",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Strict table unique on (title_norm, join_year)\n",
    "titles_strict = titles_df[[\"title_norm\", \"join_year\", *meta_cols]].copy()\n",
    "dups_strict = titles_strict.duplicated([\"title_norm\", \"join_year\"]).sum()\n",
    "if dups_strict:\n",
    "    # keep the first occurrence; you can change policy if you want\n",
    "    titles_strict = titles_strict.drop_duplicates([\"title_norm\", \"join_year\"], keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00b25c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loose table unique on title_norm only\n",
    "titles_loose = titles_df[[\"title_norm\", *meta_cols]].copy()\n",
    "dups_loose = titles_loose.duplicated([\"title_norm\"]).sum()\n",
    "if dups_loose:\n",
    "    titles_loose = titles_loose.drop_duplicates([\"title_norm\"], keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47814b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict duplicates removed: 4\n",
      "Loose duplicates removed:  6\n"
     ]
    }
   ],
   "source": [
    "print(f\"Strict duplicates removed: {dups_strict}\")\n",
    "print(f\"Loose duplicates removed:  {dups_loose}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd90b452",
   "metadata": {},
   "source": [
    "11. Pass 1: Strict match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0415e00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDb rows total: 5283\n",
      "Strict matches:   3074\n",
      "Strict unmatched: 2209\n"
     ]
    }
   ],
   "source": [
    "strict = imdb_df.merge(\n",
    "    titles_strict,\n",
    "    left_on=[\"title_norm\",\"release_year\"],\n",
    "    right_on=[\"title_norm\",\"join_year\"],\n",
    "    how=\"left\",\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "matched_strict = strict[strict[\"_merge\"] == \"both\"].copy()\n",
    "unmatched = strict[strict[\"_merge\"] == \"left_only\"].copy()\n",
    "\n",
    "# Drop merge indicators from matched\n",
    "matched_strict.drop(columns=[\"_merge\"], inplace=True)\n",
    "\n",
    "# Drop failed merge columns from unmatched\n",
    "unmatched.drop(columns=[\n",
    "    c for c in unmatched.columns if c in meta_cols or c in (\"join_year\",\"_merge\")\n",
    "], inplace=True, errors=\"ignore\")\n",
    "\n",
    "print(f\"IMDb rows total: {len(imdb_df)}\")\n",
    "print(f\"Strict matches:   {len(matched_strict)}\")\n",
    "print(f\"Strict unmatched: {len(unmatched)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863c8356",
   "metadata": {},
   "source": [
    "12. Pass 2: Loose match for remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f47e598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loose = unmatched.merge(\n",
    "    titles_loose,\n",
    "    on=\"title_norm\",\n",
    "    how=\"left\",\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "loose.drop(columns=[\"_merge\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33433485",
   "metadata": {},
   "source": [
    "13. Combine strict + loose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14d7cd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows enriched with at least one metadata field: 3956 / 5283 (74.9%)\n"
     ]
    }
   ],
   "source": [
    "combined = pd.concat([matched_strict, loose], ignore_index=True, sort=False)\n",
    "\n",
    "# Drop join_year after merge\n",
    "combined.drop(columns=[\"join_year\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "# How many rows got *any* metadata\n",
    "got_any_meta = combined[meta_cols].notna().any(axis=1).sum()\n",
    "print(f\"Rows enriched with at least one metadata field: \"\n",
    "      f\"{got_any_meta} / {len(combined)} \"\n",
    "      f\"({got_any_meta/len(combined):.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5050f44",
   "metadata": {},
   "source": [
    "14. Save outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fb768fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved files:\n",
      "- ../data/processed/netflix_merged_strict_only.csv\n",
      "- ../data/processed/netflix_merged_strict_then_loose.csv\n",
      "- ../data/interim/unmatched_after_loose.csv\n"
     ]
    }
   ],
   "source": [
    "Path(\"../data/processed\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"../data/interim\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "strict_only_path = \"../data/processed/netflix_merged_strict_only.csv\"\n",
    "combined_path    = \"../data/processed/netflix_merged_strict_then_loose.csv\"\n",
    "unmatched_path   = \"../data/interim/unmatched_after_loose.csv\"\n",
    "\n",
    "matched_strict.to_csv(strict_only_path, index=False)\n",
    "combined.to_csv(combined_path, index=False)\n",
    "\n",
    "still_unenriched = combined[combined[meta_cols].isna().all(axis=1)]\n",
    "still_unenriched.to_csv(unmatched_path, index=False)\n",
    "\n",
    "print(\"\\nSaved files:\")\n",
    "print(\"-\", strict_only_path)\n",
    "print(\"-\", combined_path)\n",
    "print(\"-\", unmatched_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607c3b92",
   "metadata": {},
   "source": [
    "15. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1734971a",
   "metadata": {},
   "source": [
    "What we’ve learned so far\n",
    "\n",
    "\t•\tRows in IMDb: 5,283\n",
    "\t•\tStrict match (title + year): 3,074 rows (~58%)\n",
    "\t•\tStrict + loose (title only): 3,956 rows with at least one metadata field (~75%)\n",
    "\t•\tStill missing all metadata after both passes: ~25%\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "\t•\tThe Netflix Titles catalog only partially overlaps with the IMDb list (different availability/regions/years).\n",
    "\t•\tThe loose pass buys ~17% more rows with metadata, but also risks minor mis-matches (remakes, different years, same title different entities).\n",
    "\t•\tFor modeling quality, I’d prefer strict-only (clean labels). For EDA and the future app, the combined file is useful to show directors/genres/etc. on more rows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "netflix-imdb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
